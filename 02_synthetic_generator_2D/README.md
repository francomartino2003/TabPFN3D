# Synthetic Dataset Generator for TabPFN

This module implements a synthetic tabular dataset generator following the methodology described in the TabPFN paper.

## Overview

The key idea is to generate many different datasets, each from a different generative process, to train a model that learns to solve tabular problems in general.

Each dataset is generated by:
1. **Building a causal DAG** - A directed acyclic graph defines the structure
2. **Defining transformations** - Each edge applies NN, tree, or discretization transforms
3. **Propagating noise** - Inject noise at roots and propagate through the graph
4. **Selecting features/target** - Choose which nodes become observed columns
5. **Post-processing** - Apply warping, quantization, missing values

## Quick Start

```python
from generator import SyntheticDatasetGenerator
from config import PriorConfig

# Create generator with default prior
generator = SyntheticDatasetGenerator(seed=42)

# Generate a single dataset
dataset = generator.generate()
X, y = dataset.X, dataset.y

print(f"Shape: {X.shape}")
print(f"Task: {'Classification' if dataset.is_classification else 'Regression'}")
print(f"Relevant features: {dataset.metadata['n_relevant_features']}")
```

## Custom Prior Configuration

```python
# Create a custom prior for specific dataset characteristics
custom_prior = PriorConfig(
    n_rows_range=(100, 1000),       # Dataset size
    n_features_range=(5, 20),        # Number of features
    n_nodes_range=(20, 50),          # DAG complexity
    prob_classification=0.7,         # 70% classification tasks
    prob_missing_values=0.3,         # 30% chance of missing values
    prob_warping=0.5,                # 50% chance of warping
)

generator = SyntheticDatasetGenerator(prior=custom_prior)
```

## Generate Many Datasets

```python
# Generate 1000 datasets for training
for i, dataset in enumerate(generator.generate_many(1000)):
    # Use dataset for training
    X, y = dataset.X, dataset.y
    # ...
```

## Module Structure

- `config.py` - Configuration classes (`PriorConfig`, `DatasetConfig`)
- `dag_builder.py` - DAG construction with preferential attachment
- `transformations.py` - Edge transformations (NN, tree, discretization)
- `row_generator.py` - Noise propagation through the DAG
- `feature_selector.py` - Feature and target selection
- `post_processing.py` - Warping, quantization, missing values
- `generator.py` - Main generator class
- `demo.py` - Demonstration script
- `tests.py` - Unit tests

## Key Concepts

### Causal DAG Structure

The DAG defines relationships between latent variables:
- **Root nodes**: Receive injected noise (normal, uniform, mixture)
- **Internal nodes**: Combine parent values through transformations
- **Disconnected subgraphs**: Create irrelevant features

### Edge Transformations

Four types of transformations:
1. **NN-like**: Linear combination + nonlinear activation
2. **Decision tree**: Piecewise constant rules
3. **Discretization**: Categorical feature creation
4. **Identity**: Weighted sum with noise

### Feature Selection

- Target is selected from the main subgraph (has ancestors)
- Features can be **relevant** (ancestors of target) or **irrelevant** (from disconnected subgraphs)
- This tests a model's ability to identify what matters

### Post-Processing

Applies realistic distortions:
- **Warping**: Power transforms, sinh-arcsinh, periodic perturbations
- **Quantization**: Binning continuous values
- **Missing values**: MCAR (Missing Completely At Random)

## Hyperparameters to Experiment With

As noted in the paper, many aspects are not fixed and should be varied:

| Category | Parameters |
|----------|------------|
| Size | `n_rows_range`, `n_features_range` |
| Graph | `n_nodes_range`, `density_gamma_*`, `prob_disconnected_subgraph` |
| Transforms | `prob_nn_transform`, `prob_tree_transform`, activation sets |
| Noise | `noise_types`, `noise_scale_range` |
| Post-processing | `prob_warping`, `prob_quantization`, `prob_missing_values` |

## Running Tests

```bash
python synthetic_generator/tests.py
```

## Running Demo

```bash
python synthetic_generator/demo.py
```

## Future Extensions

This implementation is designed to be extended to 3D datasets. The main changes for 3D would be:
- Modify node transformations to handle 3D structures
- Add spatial relationships in the DAG
- Extend post-processing for 3D-specific distortions

